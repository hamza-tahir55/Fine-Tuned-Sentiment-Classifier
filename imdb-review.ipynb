{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30841,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets torch\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T10:56:34.278221Z","iopub.execute_input":"2025-01-29T10:56:34.278432Z","iopub.status.idle":"2025-01-29T10:56:38.627919Z","shell.execute_reply.started":"2025-01-29T10:56:34.278403Z","shell.execute_reply":"2025-01-29T10:56:38.626931Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, DistilBertConfig\n\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n\nconfig = DistilBertConfig.from_pretrained(\n    \"distilbert-base-uncased\", \n    attention_probs_dropout_prob=0.4,  # Higher dropout for attention\n    hidden_dropout_prob=0.4           # Higher dropout for hidden layers\n)\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\", config=config)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T11:57:51.866014Z","iopub.execute_input":"2025-01-29T11:57:51.866321Z","iopub.status.idle":"2025-01-29T11:58:17.593866Z","shell.execute_reply.started":"2025-01-29T11:57:51.866296Z","shell.execute_reply":"2025-01-29T11:58:17.593001Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35904be88ebd40488bd9301c178e10d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"115380b59ab046808be784a15a894f1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58ffae10cd4b41b4a5067c3fe1e5c92e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09dbe22d78904dea8455c34b89779383"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d44dd534d4b4c8982cead6395ecc447"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from datasets import load_dataset\n\n\nds = load_dataset(\"jahjinx/IMDb_movie_reviews\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T11:58:17.594900Z","iopub.execute_input":"2025-01-29T11:58:17.595439Z","iopub.status.idle":"2025-01-29T11:58:22.209876Z","shell.execute_reply.started":"2025-01-29T11:58:17.595411Z","shell.execute_reply":"2025-01-29T11:58:22.208833Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/4.24k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b617ba0f237445182a632c7c13fbdce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"IMDB_train.csv:   0%|          | 0.00/47.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"762c9d8bd6f544c48f87635692718d85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"IMDB_validation.csv:   0%|          | 0.00/5.23M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"045c73c48fda44c595ef82b95e002bdb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"IMDB_test.csv:   0%|          | 0.00/13.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c076c484d53b42a7afc79af8465a1fee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/36000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e40217ad6c884458892ab9af37f76959"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/4000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47915787f22643e9ac1fdfb6f1a35bd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4da9b2e0c3554cab824b5baffa711804"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"ds[\"train\"].to_csv(\"IMDB_train.csv\")\nds[\"validation\"].to_csv(\"IMDB_validation.csv\")\nds[\"test\"].to_csv(\"IMDB_test.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T11:58:22.211732Z","iopub.execute_input":"2025-01-29T11:58:22.212194Z","iopub.status.idle":"2025-01-29T11:58:23.601999Z","shell.execute_reply.started":"2025-01-29T11:58:22.212170Z","shell.execute_reply":"2025-01-29T11:58:23.601210Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Creating CSV from Arrow format:   0%|          | 0/36 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4403de9786d24edbbe1190bf9535c893"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating CSV from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9a66f1e5a8e4ca396731ffa6de56bde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating CSV from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9da8c7219d034dd2995a46c558eeaa4a"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"13035905"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\n\ntrain_df = pd.DataFrame(ds[\"train\"])\nvalidation_df = pd.DataFrame(ds[\"validation\"])\ntest_df = pd.DataFrame(ds[\"test\"])\n\n# Combine datasets\ncomplete_df = pd.concat([train_df, validation_df, test_df], ignore_index=True)\ncomplete_df.to_csv(\"complete_IMDB_dataset.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T11:58:23.603090Z","iopub.execute_input":"2025-01-29T11:58:23.603337Z","iopub.status.idle":"2025-01-29T11:58:25.901174Z","shell.execute_reply.started":"2025-01-29T11:58:23.603317Z","shell.execute_reply":"2025-01-29T11:58:25.900513Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"complete_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T11:58:25.902132Z","iopub.execute_input":"2025-01-29T11:58:25.902474Z","iopub.status.idle":"2025-01-29T11:58:25.921016Z","shell.execute_reply.started":"2025-01-29T11:58:25.902444Z","shell.execute_reply":"2025-01-29T11:58:25.920299Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                    text  label\n0      Beautifully photographed and ably acted, gener...      0\n1      Well, where to start describing this celluloid...      0\n2      I first caught the movie on its first run on H...      1\n3      I love Umberto Lenzi's cop movies -- ROME ARME...      0\n4      I generally won't review movies I haven't seen...      0\n...                                                  ...    ...\n49995  I liked this movie. That's pretty much all I c...      1\n49996  Imagine the plight of Richard, a painter, whos...      1\n49997  There is an inherent problem with commenting o...      0\n49998  When The Matrix appeared in 1999 and questione...      1\n49999  Ohhhh MAN this movie is awful!!<br /><br />Thi...      0\n\n[50000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Beautifully photographed and ably acted, gener...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Well, where to start describing this celluloid...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I first caught the movie on its first run on H...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I love Umberto Lenzi's cop movies -- ROME ARME...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I generally won't review movies I haven't seen...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>I liked this movie. That's pretty much all I c...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>Imagine the plight of Richard, a painter, whos...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>There is an inherent problem with commenting o...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>When The Matrix appeared in 1999 and questione...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>Ohhhh MAN this movie is awful!!&lt;br /&gt;&lt;br /&gt;Thi...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split into training, validation, and test subsets\ntrain_df, temp_df = train_test_split(complete_df, train_size=0.7, random_state=42)\nval_df, test_df = train_test_split(temp_df, train_size=0.5, random_state=42)\n\nprint(f\"Train: {len(train_df)}, Validation: {len(val_df)}, Test: {len(test_df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T11:58:25.921744Z","iopub.execute_input":"2025-01-29T11:58:25.921974Z","iopub.status.idle":"2025-01-29T11:58:25.948302Z","shell.execute_reply.started":"2025-01-29T11:58:25.921944Z","shell.execute_reply":"2025-01-29T11:58:25.947676Z"}},"outputs":[{"name":"stdout","text":"Train: 35000, Validation: 7500, Test: 7500\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from datasets import Dataset\n\ntrain_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)\ntest_dataset = Dataset.from_pandas(test_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T11:58:25.949016Z","iopub.execute_input":"2025-01-29T11:58:25.949222Z","iopub.status.idle":"2025-01-29T11:58:26.501018Z","shell.execute_reply.started":"2025-01-29T11:58:25.949194Z","shell.execute_reply":"2025-01-29T11:58:26.500065Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def tokenize_function(batch):\n    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\nencoded_train = train_dataset.map(tokenize_function, batched=True)\nencoded_val = val_dataset.map(tokenize_function, batched=True)\nencoded_test = test_dataset.map(tokenize_function, batched=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T11:58:26.502788Z","iopub.execute_input":"2025-01-29T11:58:26.503038Z","iopub.status.idle":"2025-01-29T11:58:48.202870Z","shell.execute_reply.started":"2025-01-29T11:58:26.503016Z","shell.execute_reply":"2025-01-29T11:58:48.201992Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/35000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4962d14ed7b4694a88196712045fb71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d522e812a9df41ed9c1b07a690ad784d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac8f4a7ea0a447a0a2886f8ed9927e84"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert-base-uncased\",\n    num_labels=2  # Positive and Negative sentiment labels\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T11:58:48.203845Z","iopub.execute_input":"2025-01-29T11:58:48.204083Z","iopub.status.idle":"2025-01-29T11:58:49.758557Z","shell.execute_reply.started":"2025-01-29T11:58:48.204061Z","shell.execute_reply":"2025-01-29T11:58:49.757702Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af1761a57d3e40ef8930ecb420419d6a"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=1e-6,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=2,  # Train for only 1 epoch\n    weight_decay=0.1,\n    logging_dir=\"./logs\",\n    logging_steps=200,\n    save_total_limit=2,\n    save_strategy=\"epoch\",\n    fp16=True,\n    report_to=\"none\",\n    load_best_model_at_end=True,  # Still useful if you save checkpoints\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T11:58:49.759533Z","iopub.execute_input":"2025-01-29T11:58:49.759817Z","iopub.status.idle":"2025-01-29T11:58:49.900753Z","shell.execute_reply.started":"2025-01-29T11:58:49.759784Z","shell.execute_reply":"2025-01-29T11:58:49.899826Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=encoded_train,\n    eval_dataset=encoded_val,\n    tokenizer=tokenizer,\n\n\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T11:58:56.627812Z","iopub.execute_input":"2025-01-29T11:58:56.628117Z","iopub.status.idle":"2025-01-29T11:58:56.643734Z","shell.execute_reply.started":"2025-01-29T11:58:56.628092Z","shell.execute_reply":"2025-01-29T11:58:56.642900Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-16-76816ea5a368>:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"!nvidia-smi\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:14:29.252080Z","iopub.execute_input":"2025-01-29T12:14:29.252439Z","iopub.status.idle":"2025-01-29T12:14:29.461023Z","shell.execute_reply.started":"2025-01-29T12:14:29.252403Z","shell.execute_reply":"2025-01-29T12:14:29.460162Z"}},"outputs":[{"name":"stdout","text":"Wed Jan 29 12:14:29 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   38C    P0             30W /  250W |    1797MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"trainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T11:58:59.971122Z","iopub.execute_input":"2025-01-29T11:58:59.971503Z","iopub.status.idle":"2025-01-29T12:07:10.662806Z","shell.execute_reply.started":"2025-01-29T11:58:59.971470Z","shell.execute_reply":"2025-01-29T12:07:10.661904Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4376' max='4376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4376/4376 08:09, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.386500</td>\n      <td>0.374528</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.362700</td>\n      <td>0.362805</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=4376, training_loss=0.41094621748985277, metrics={'train_runtime': 490.2953, 'train_samples_per_second': 142.771, 'train_steps_per_second': 8.925, 'total_flos': 2318179476480000.0, 'train_loss': 0.41094621748985277, 'epoch': 2.0})"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"trainer.evaluate()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:14:32.420871Z","iopub.execute_input":"2025-01-29T12:14:32.421208Z","iopub.status.idle":"2025-01-29T12:14:47.028251Z","shell.execute_reply.started":"2025-01-29T12:14:32.421175Z","shell.execute_reply":"2025-01-29T12:14:47.027551Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.36280521750450134,\n 'eval_runtime': 14.5969,\n 'eval_samples_per_second': 513.808,\n 'eval_steps_per_second': 32.13,\n 'epoch': 2.0}"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n# Save model and tokenizer using the Hugging Face API\nmodel.save_pretrained(\"./IMDB_fine_tuned_model\")\ntokenizer.save_pretrained(\"./IMDB_fine_tuned_model_tokenizer\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:09:44.533436Z","iopub.execute_input":"2025-01-29T12:09:44.533743Z","iopub.status.idle":"2025-01-29T12:09:45.455558Z","shell.execute_reply.started":"2025-01-29T12:09:44.533722Z","shell.execute_reply":"2025-01-29T12:09:45.454757Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"('./IMDB_fine_tuned_model_tokenizer/tokenizer_config.json',\n './IMDB_fine_tuned_model_tokenizer/special_tokens_map.json',\n './IMDB_fine_tuned_model_tokenizer/vocab.txt',\n './IMDB_fine_tuned_model_tokenizer/added_tokens.json',\n './IMDB_fine_tuned_model_tokenizer/tokenizer.json')"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"!zip -r IMDB_fine_tuned_model.zip ./IMDB_fine_tuned_model\n!zip -r IMDB_fine_tuned_model_tokenizer.zip ./IMDB_fine_tuned_model_tokenizer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:09:54.270871Z","iopub.execute_input":"2025-01-29T12:09:54.271195Z","iopub.status.idle":"2025-01-29T12:10:08.444787Z","shell.execute_reply.started":"2025-01-29T12:09:54.271168Z","shell.execute_reply":"2025-01-29T12:10:08.443956Z"}},"outputs":[{"name":"stdout","text":"  adding: IMDB_fine_tuned_model/ (stored 0%)\n  adding: IMDB_fine_tuned_model/vocab.txt (deflated 53%)\n  adding: IMDB_fine_tuned_model/special_tokens_map.json (deflated 42%)\n  adding: IMDB_fine_tuned_model/tokenizer.json (deflated 71%)\n  adding: IMDB_fine_tuned_model/model.safetensors (deflated 8%)\n  adding: IMDB_fine_tuned_model/training_args.bin (deflated 51%)\n  adding: IMDB_fine_tuned_model/tokenizer_config.json (deflated 75%)\n  adding: IMDB_fine_tuned_model/config.json (deflated 46%)\n  adding: IMDB_fine_tuned_model_tokenizer/ (stored 0%)\n  adding: IMDB_fine_tuned_model_tokenizer/vocab.txt (deflated 53%)\n  adding: IMDB_fine_tuned_model_tokenizer/special_tokens_map.json (deflated 42%)\n  adding: IMDB_fine_tuned_model_tokenizer/tokenizer.json (deflated 71%)\n  adding: IMDB_fine_tuned_model_tokenizer/tokenizer_config.json (deflated 75%)\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"\n\nfrom transformers import AutoModelForSequenceClassification\n\n# Save the fine-tuned model explicitly\nmodel.save_pretrained(\"./IMDB_fine_tuned_model\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:16:22.606868Z","iopub.execute_input":"2025-01-29T12:16:22.607157Z","iopub.status.idle":"2025-01-29T12:16:23.531024Z","shell.execute_reply.started":"2025-01-29T12:16:22.607134Z","shell.execute_reply":"2025-01-29T12:16:23.530075Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"!zip -r IMDB_fine_tuned_model.zip ./IMDB_fine_tuned_model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:16:27.784949Z","iopub.execute_input":"2025-01-29T12:16:27.785247Z","iopub.status.idle":"2025-01-29T12:16:41.843959Z","shell.execute_reply.started":"2025-01-29T12:16:27.785206Z","shell.execute_reply":"2025-01-29T12:16:41.842948Z"}},"outputs":[{"name":"stdout","text":"updating: IMDB_fine_tuned_model/ (stored 0%)\nupdating: IMDB_fine_tuned_model/vocab.txt (deflated 53%)\nupdating: IMDB_fine_tuned_model/special_tokens_map.json (deflated 42%)\nupdating: IMDB_fine_tuned_model/tokenizer.json (deflated 71%)\nupdating: IMDB_fine_tuned_model/model.safetensors (deflated 8%)\nupdating: IMDB_fine_tuned_model/training_args.bin (deflated 51%)\nupdating: IMDB_fine_tuned_model/tokenizer_config.json (deflated 75%)\nupdating: IMDB_fine_tuned_model/config.json (deflated 46%)\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}